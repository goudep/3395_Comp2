{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12793c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境配置完成。\n",
      "正在加载数据...\n",
      "加载文件: ./data\\train_data.pkl, 原始形状: (1080, 3, 28, 28)\n",
      "加载文件: ./data\\test_data.pkl, 原始形状: (400, 3, 28, 28)\n",
      "最终输入特征维度 (INPUT_SIZE): 2352\n",
      "数据标准化完成。\n",
      "\n",
      "开始训练集成模型 (共 5 个)...\n",
      "--- Training Model 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yudim\\AppData\\Local\\Temp\\ipykernel_22068\\2484305379.py:112: RuntimeWarning: overflow encountered in dot\n",
      "  scores = h1.dot(W2) + b2\n",
      "C:\\Users\\yudim\\AppData\\Local\\Temp\\ipykernel_22068\\2484305379.py:118: RuntimeWarning: invalid value encountered in subtract\n",
      "  shifted_scores = scores - np.max(scores, axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Val Acc: 0.4259\n",
      "--- Training Model 2 ---\n",
      "Model 2 Val Acc: 0.4630\n",
      "--- Training Model 3 ---\n",
      "Model 3 Val Acc: 0.4861\n",
      "--- Training Model 4 ---\n",
      "Model 4 Val Acc: 0.4120\n",
      "--- Training Model 5 ---\n",
      "Model 5 Val Acc: 0.4630\n",
      "\n",
      "正在生成最终预测...\n",
      "成功生成: submission_ensemble_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================= 配置区域 =================\n",
    "DATA_DIR = './data'\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, 'train_data.pkl')\n",
    "TEST_PATH = os.path.join(DATA_DIR, 'test_data.pkl')\n",
    "\n",
    "# 训练超参数\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_CLASSES = 5\n",
    "LEARNING_RATE = 0.05\n",
    "MOMENTUM = 0.9\n",
    "REG = 0.001\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 40\n",
    "NUM_MODELS = 5\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"环境配置完成。\")\n",
    "\n",
    "# ================= 数据处理工具 =================\n",
    "def load_and_process_data(path, has_labels=True, target_max_size=64):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"{path} 未找到\")\n",
    "    \n",
    "    # 修正点：确保这里没有多余的符号\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    images = np.array(data['images'])\n",
    "    \n",
    "    # 确保格式为 (N, C, H, W)\n",
    "    if images.shape[-1] == 3:\n",
    "        images = images.transpose(0, 3, 1, 2)\n",
    "    \n",
    "    N, C, H, W = images.shape\n",
    "    print(f\"加载文件: {path}, 原始形状: {images.shape}\")\n",
    "    \n",
    "    # 动态计算步长，防止除以0错误\n",
    "    h_step = max(1, H // target_max_size)\n",
    "    w_step = max(1, W // target_max_size)\n",
    "    \n",
    "    # 执行切片降采样\n",
    "    images_processed = images[:, :, ::h_step, ::w_step]\n",
    "    \n",
    "    # 归一化 [0, 1]\n",
    "    X = images_processed.astype(float) / 255.0\n",
    "    \n",
    "    # 展平\n",
    "    X_flat = X.reshape(N, -1)\n",
    "    \n",
    "    y = np.array(data['labels']) if has_labels else None\n",
    "    \n",
    "    return X_flat, y, images_processed.shape[1:]\n",
    "\n",
    "def augment_batch(X_batch, img_shape):\n",
    "    \"\"\"随机水平翻转 (Data Augmentation)\"\"\"\n",
    "    N = X_batch.shape[0]\n",
    "    C, H, W = img_shape\n",
    "    \n",
    "    mask = np.random.rand(N) > 0.5\n",
    "    if not np.any(mask):\n",
    "        return X_batch\n",
    "    \n",
    "    X_img = X_batch.reshape(N, C, H, W)\n",
    "    # 翻转宽度维度\n",
    "    X_img[mask] = X_img[mask, :, :, ::-1]\n",
    "    \n",
    "    return X_img.reshape(N, -1)\n",
    "\n",
    "# ================= 1. 加载数据 =================\n",
    "print(\"正在加载数据...\")\n",
    "# [cite_start]加载训练集 [cite: 14]\n",
    "X_train_all, y_train_all, img_shape = load_and_process_data(TRAIN_PATH, has_labels=True)\n",
    "# [cite_start]加载测试集 [cite: 16]\n",
    "X_test_raw, _, _ = load_and_process_data(TEST_PATH, has_labels=False)\n",
    "\n",
    "INPUT_SIZE = X_train_all.shape[1]\n",
    "print(f\"最终输入特征维度 (INPUT_SIZE): {INPUT_SIZE}\")\n",
    "\n",
    "# 全局标准化\n",
    "mean_vals = np.mean(X_train_all, axis=0)\n",
    "std_vals = np.std(X_train_all, axis=0) + 1e-7\n",
    "\n",
    "X_train_all = (X_train_all - mean_vals) / std_vals\n",
    "X_test_norm = (X_test_raw - mean_vals) / std_vals\n",
    "print(\"数据标准化完成。\")\n",
    "\n",
    "# ================= 2. 定义模型 (NumPy Only) =================\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, std=1e-2):\n",
    "        self.params = {}\n",
    "        # He Initialization\n",
    "        self.params['W1'] = np.random.randn(input_dim, hidden_dim) * np.sqrt(2.0/input_dim)\n",
    "        self.params['b1'] = np.zeros(hidden_dim)\n",
    "        self.params['W2'] = np.random.randn(hidden_dim, output_dim) * np.sqrt(2.0/hidden_dim)\n",
    "        self.params['b2'] = np.zeros(output_dim)\n",
    "        \n",
    "        self.v = {k: np.zeros_like(v) for k, v in self.params.items()}\n",
    "\n",
    "    def loss(self, X, y=None, reg=0.0):\n",
    "        W1, b1 = self.params['W1'], self.params['b1']\n",
    "        W2, b2 = self.params['W2'], self.params['b2']\n",
    "        N = X.shape[0]\n",
    "\n",
    "        # Forward\n",
    "        h1 = np.maximum(0, X.dot(W1) + b1)\n",
    "        scores = h1.dot(W2) + b2\n",
    "        \n",
    "        if y is None:\n",
    "            return scores\n",
    "\n",
    "        # Softmax Loss\n",
    "        shifted_scores = scores - np.max(scores, axis=1, keepdims=True)\n",
    "        exp_scores = np.exp(shifted_scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        \n",
    "        correct_logprobs = -np.log(probs[np.arange(N), y] + 1e-9)\n",
    "        loss = np.sum(correct_logprobs) / N\n",
    "        loss += 0.5 * reg * (np.sum(W1*W1) + np.sum(W2*W2))\n",
    "\n",
    "        # Backward\n",
    "        grads = {}\n",
    "        dscores = probs\n",
    "        dscores[np.arange(N), y] -= 1\n",
    "        dscores /= N\n",
    "\n",
    "        grads['W2'] = h1.T.dot(dscores) + reg * W2\n",
    "        grads['b2'] = np.sum(dscores, axis=0)\n",
    "\n",
    "        dh1 = dscores.dot(W2.T)\n",
    "        dh1[h1 <= 0] = 0\n",
    "\n",
    "        grads['W1'] = X.T.dot(dh1) + reg * W1\n",
    "        grads['b1'] = np.sum(dh1, axis=0)\n",
    "\n",
    "        return loss, grads\n",
    "\n",
    "    def update(self, grads, learning_rate, momentum=0.9):\n",
    "        for p in self.params:\n",
    "            self.v[p] = momentum * self.v[p] - learning_rate * grads[p]\n",
    "            self.params[p] += self.v[p]\n",
    "\n",
    "    def predict_scores(self, X):\n",
    "        return self.loss(X)\n",
    "\n",
    "# ================= 3. 集成训练 (5 Models) =================\n",
    "models = []\n",
    "print(f\"\\n开始训练集成模型 (共 {NUM_MODELS} 个)...\")\n",
    "\n",
    "indices = np.arange(len(X_train_all))\n",
    "fold_size = len(X_train_all) // NUM_MODELS\n",
    "\n",
    "for i in range(NUM_MODELS):\n",
    "    # 划分 Fold\n",
    "    val_idx = indices[i*fold_size : (i+1)*fold_size]\n",
    "    train_idx = np.concatenate([indices[:i*fold_size], indices[(i+1)*fold_size:]])\n",
    "    \n",
    "    X_tr_fold = X_train_all[train_idx]\n",
    "    y_tr_fold = y_train_all[train_idx]\n",
    "    X_val_fold = X_train_all[val_idx]\n",
    "    y_val_fold = y_train_all[val_idx]\n",
    "    \n",
    "    print(f\"--- Training Model {i+1} ---\")\n",
    "    net = TwoLayerNet(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES)\n",
    "    \n",
    "    iter_per_epoch = max(len(X_tr_fold) // BATCH_SIZE, 1)\n",
    "    num_iters = EPOCHS * iter_per_epoch\n",
    "    current_lr = LEARNING_RATE\n",
    "    \n",
    "    for it in range(num_iters):\n",
    "        batch_mask = np.random.choice(len(X_tr_fold), BATCH_SIZE)\n",
    "        X_batch = X_tr_fold[batch_mask]\n",
    "        y_batch = y_tr_fold[batch_mask]\n",
    "        \n",
    "        # Augment\n",
    "        X_batch_aug = augment_batch(X_batch, img_shape)\n",
    "        \n",
    "        loss, grads = net.loss(X_batch_aug, y_batch, reg=REG)\n",
    "        net.update(grads, current_lr, momentum=MOMENTUM)\n",
    "        \n",
    "        if it > 0 and it % (10 * iter_per_epoch) == 0:\n",
    "            current_lr *= 0.8\n",
    "            \n",
    "    val_preds = np.argmax(net.predict_scores(X_val_fold), axis=1)\n",
    "    acc = np.mean(val_preds == y_val_fold)\n",
    "    print(f\"Model {i+1} Val Acc: {acc:.4f}\")\n",
    "    \n",
    "    models.append(net)\n",
    "\n",
    "# ================= 4. 预测与提交 =================\n",
    "print(\"\\n正在生成最终预测...\")\n",
    "total_scores = np.zeros((X_test_norm.shape[0], NUM_CLASSES))\n",
    "\n",
    "for net in models:\n",
    "    total_scores += net.predict_scores(X_test_norm)\n",
    "\n",
    "final_predictions = np.argmax(total_scores, axis=1)\n",
    "\n",
    "filename = 'submission_ensemble_fixed.csv'\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ID', 'Label'])\n",
    "    for i, label in enumerate(final_predictions):\n",
    "        writer.writerow([i + 1, label])\n",
    "\n",
    "print(f\"成功生成: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
