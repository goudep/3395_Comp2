{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# IFT3395 Competition 2 - Milestone 2 v4\n",
                "\n",
                "## 目标: Validation Accuracy > 0.53, 训练时间 < 15分钟\n",
                "\n",
                "## 策略\n",
                "- **ResBlock CNN**: 残差连接提高性能\n",
                "- **4模型集成**: CNN + ET + RF + HistGradientBoosting\n",
                "- **5折CV**: 更稳定的验证\n",
                "- **多特征**: 像素 + 颜色统计"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Device: cpu\n"
                    ]
                }
            ],
            "source": [
                "# Cell 1: Imports\n",
                "import pickle\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import random, os, warnings, time\n",
                "from PIL import Image\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
                "from torchvision import transforms\n",
                "\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "SEED = 42\n",
                "def seed_all(seed):\n",
                "    random.seed(seed)\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed(seed)\n",
                "        torch.backends.cudnn.deterministic = True\n",
                "\n",
                "seed_all(SEED)\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "t0 = time.time()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train: (1080, 28, 28, 3), Test: (400, 28, 28, 3)\n",
                        "Classes: [486 128 206 194  66]\n"
                    ]
                }
            ],
            "source": [
                "# Cell 2: Load Data\n",
                "DATA_DIR = Path('data')\n",
                "with open(DATA_DIR / 'train_data.pkl', 'rb') as f:\n",
                "    train_data = pickle.load(f)\n",
                "with open(DATA_DIR / 'test_data.pkl', 'rb') as f:\n",
                "    test_data = pickle.load(f)\n",
                "\n",
                "X_train = train_data['images']\n",
                "y_train = train_data['labels'].flatten().astype(np.int64)\n",
                "X_test = test_data['images']\n",
                "\n",
                "if X_train.max() <= 1.0:\n",
                "    X_train = (X_train * 255).astype(np.uint8)\n",
                "    X_test = (X_test * 255).astype(np.uint8)\n",
                "else:\n",
                "    X_train = X_train.astype(np.uint8)\n",
                "    X_test = X_test.astype(np.uint8)\n",
                "\n",
                "n_train, n_test = len(X_train), len(X_test)\n",
                "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
                "print(f\"Classes: {np.bincount(y_train)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting features...\n",
                        "Feature shape: (1080, 2374)\n"
                    ]
                }
            ],
            "source": [
                "# Cell 3: Feature Engineering (No skimage needed)\n",
                "def extract_features(images):\n",
                "    \"\"\"Extract features: flatten pixels + color statistics\"\"\"\n",
                "    features = []\n",
                "    for img in images:\n",
                "        # Flatten RGB pixels\n",
                "        flat = img.flatten().astype(np.float32) / 255.0\n",
                "        \n",
                "        # Color statistics per channel\n",
                "        stats = []\n",
                "        for c in range(3):\n",
                "            ch = img[:, :, c].astype(np.float32)\n",
                "            stats.extend([ch.mean(), ch.std(), ch.min(), ch.max(),\n",
                "                          np.percentile(ch, 25), np.percentile(ch, 75)])\n",
                "        \n",
                "        # Grayscale stats\n",
                "        gray = 0.299*img[:,:,0] + 0.587*img[:,:,1] + 0.114*img[:,:,2]\n",
                "        stats.extend([gray.mean(), gray.std(), gray.min(), gray.max()])\n",
                "        \n",
                "        # Combine\n",
                "        features.append(np.concatenate([flat, np.array(stats, dtype=np.float32)]))\n",
                "    return np.array(features, dtype=np.float32)\n",
                "\n",
                "print(\"Extracting features...\")\n",
                "X_train_feat = extract_features(X_train)\n",
                "X_test_feat = extract_features(X_test)\n",
                "print(f\"Feature shape: {X_train_feat.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model defined.\n"
                    ]
                }
            ],
            "source": [
                "# Cell 4: Dataset & CNN Model\n",
                "class ImgDataset(Dataset):\n",
                "    def __init__(self, images, labels=None, transform=None):\n",
                "        self.images = images\n",
                "        self.labels = labels\n",
                "        self.transform = transform\n",
                "        \n",
                "    def __len__(self): return len(self.images)\n",
                "    \n",
                "    def __getitem__(self, i):\n",
                "        img = Image.fromarray(self.images[i].astype(np.uint8))\n",
                "        if self.transform: img = self.transform(img)\n",
                "        if self.labels is not None:\n",
                "            return img, torch.tensor(self.labels[i], dtype=torch.long)\n",
                "        return img\n",
                "\n",
                "train_tf = transforms.Compose([\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(15),\n",
                "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "val_tf = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "class ResBlock(nn.Module):\n",
                "    def __init__(self, ch):\n",
                "        super().__init__()\n",
                "        self.conv1 = nn.Conv2d(ch, ch, 3, padding=1, bias=False)\n",
                "        self.bn1 = nn.BatchNorm2d(ch)\n",
                "        self.conv2 = nn.Conv2d(ch, ch, 3, padding=1, bias=False)\n",
                "        self.bn2 = nn.BatchNorm2d(ch)\n",
                "    def forward(self, x):\n",
                "        return F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x))))) + x)\n",
                "\n",
                "class CNN(nn.Module):\n",
                "    def __init__(self, nc=5):\n",
                "        super().__init__()\n",
                "        self.layers = nn.Sequential(\n",
                "            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            ResBlock(64),\n",
                "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            ResBlock(128),\n",
                "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
                "            nn.AdaptiveAvgPool2d(1),\n",
                "            nn.Flatten(),\n",
                "            nn.Dropout(0.4),\n",
                "            nn.Linear(256, nc)\n",
                "        )\n",
                "    def forward(self, x): return self.layers(x)\n",
                "\n",
                "print(\"Model defined.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Helpers defined.\n"
                    ]
                }
            ],
            "source": [
                "# Cell 5: Helpers\n",
                "def get_sampler(y):\n",
                "    w = 1.0 / np.maximum(np.bincount(y), 1)\n",
                "    return WeightedRandomSampler(torch.from_numpy(w[y]).double(), len(y))\n",
                "\n",
                "def train_ep(model, loader, crit, opt, dev):\n",
                "    model.train()\n",
                "    for x, y in loader:\n",
                "        x, y = x.to(dev), y.to(dev)\n",
                "        opt.zero_grad()\n",
                "        loss = crit(model(x), y)\n",
                "        loss.backward()\n",
                "        opt.step()\n",
                "\n",
                "@torch.no_grad()\n",
                "def val_ep(model, loader, dev):\n",
                "    model.eval()\n",
                "    c, t, probs = 0, 0, []\n",
                "    for x, y in loader:\n",
                "        x, y = x.to(dev), y.to(dev)\n",
                "        out = model(x)\n",
                "        c += (out.argmax(1) == y).sum().item()\n",
                "        t += y.size(0)\n",
                "        probs.append(F.softmax(out, 1).cpu().numpy())\n",
                "    return c / t, np.concatenate(probs)\n",
                "\n",
                "@torch.no_grad()\n",
                "def predict(model, loader, dev):\n",
                "    model.eval()\n",
                "    probs = []\n",
                "    for x in loader:\n",
                "        probs.append(F.softmax(model(x.to(dev)), 1).cpu().numpy())\n",
                "    return np.concatenate(probs)\n",
                "\n",
                "print(\"Helpers defined.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training: 5 folds, 30 epochs\n",
                        "==================================================\n",
                        "\n",
                        "Fold 1/5\n",
                        "  CNN: 0.5324\n",
                        "  ET:  0.5324\n",
                        "  RF:  0.4815\n",
                        "  HGB: 0.5231\n",
                        "  Time: 2.9min\n",
                        "\n",
                        "Fold 2/5\n",
                        "  CNN: 0.4815\n",
                        "  ET:  0.5139\n",
                        "  RF:  0.5000\n",
                        "  HGB: 0.4815\n",
                        "  Time: 2.9min\n",
                        "\n",
                        "Fold 3/5\n",
                        "  CNN: 0.5185\n",
                        "  ET:  0.5185\n",
                        "  RF:  0.5231\n",
                        "  HGB: 0.5231\n",
                        "  Time: 3.1min\n",
                        "\n",
                        "Fold 4/5\n",
                        "  CNN: 0.5278\n",
                        "  ET:  0.4907\n",
                        "  RF:  0.5000\n",
                        "  HGB: 0.4954\n",
                        "  Time: 2.8min\n",
                        "\n",
                        "Fold 5/5\n",
                        "  CNN: 0.4537\n",
                        "  ET:  0.4722\n",
                        "  RF:  0.5093\n",
                        "  HGB: 0.4491\n",
                        "  Time: 2.4min\n",
                        "\n",
                        "Total: 14.3min\n"
                    ]
                }
            ],
            "source": [
                "# Cell 6: Training\n",
                "N_FOLDS, EPOCHS, BS = 5, 30, 64\n",
                "skf = StratifiedKFold(N_FOLDS, shuffle=True, random_state=SEED)\n",
                "\n",
                "# Storage\n",
                "cnn_oof = np.zeros((n_train, 5))\n",
                "cnn_test = np.zeros((n_test, 5))\n",
                "et_oof = np.zeros((n_train, 5))\n",
                "et_test = np.zeros((n_test, 5))\n",
                "rf_oof = np.zeros((n_train, 5))\n",
                "rf_test = np.zeros((n_test, 5))\n",
                "hgb_oof = np.zeros((n_train, 5))\n",
                "hgb_test = np.zeros((n_test, 5))\n",
                "\n",
                "print(f\"Training: {N_FOLDS} folds, {EPOCHS} epochs\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "for fold, (tr_i, val_i) in enumerate(skf.split(X_train, y_train)):\n",
                "    t1 = time.time()\n",
                "    print(f\"\\nFold {fold+1}/{N_FOLDS}\")\n",
                "    \n",
                "    # CNN\n",
                "    tr_ds = ImgDataset(X_train[tr_i], y_train[tr_i], train_tf)\n",
                "    val_ds = ImgDataset(X_train[val_i], y_train[val_i], val_tf)\n",
                "    tr_ld = DataLoader(tr_ds, BS, sampler=get_sampler(y_train[tr_i]), num_workers=0)\n",
                "    val_ld = DataLoader(val_ds, BS, shuffle=False, num_workers=0)\n",
                "    \n",
                "    model = CNN().to(device)\n",
                "    crit = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
                "    opt = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
                "    sch = optim.lr_scheduler.CosineAnnealingLR(opt, EPOCHS)\n",
                "    \n",
                "    best_acc, best_w = 0, None\n",
                "    for ep in range(EPOCHS):\n",
                "        train_ep(model, tr_ld, crit, opt, device)\n",
                "        acc, _ = val_ep(model, val_ld, device)\n",
                "        sch.step()\n",
                "        if acc > best_acc:\n",
                "            best_acc = acc\n",
                "            best_w = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
                "    \n",
                "    model.load_state_dict(best_w)\n",
                "    _, probs = val_ep(model, val_ld, device)\n",
                "    cnn_oof[val_i] = probs\n",
                "    \n",
                "    test_ds = ImgDataset(X_test, None, val_tf)\n",
                "    test_ld = DataLoader(test_ds, BS, shuffle=False, num_workers=0)\n",
                "    cnn_test += predict(model, test_ld, device) / N_FOLDS\n",
                "    print(f\"  CNN: {best_acc:.4f}\")\n",
                "    \n",
                "    # ET\n",
                "    et = ExtraTreesClassifier(200, max_depth=25, class_weight='balanced', random_state=SEED+fold, n_jobs=-1)\n",
                "    et.fit(X_train_feat[tr_i], y_train[tr_i])\n",
                "    et_oof[val_i] = et.predict_proba(X_train_feat[val_i])\n",
                "    et_test += et.predict_proba(X_test_feat) / N_FOLDS\n",
                "    print(f\"  ET:  {et.score(X_train_feat[val_i], y_train[val_i]):.4f}\")\n",
                "    \n",
                "    # RF\n",
                "    rf = RandomForestClassifier(200, max_depth=25, class_weight='balanced', random_state=SEED+fold, n_jobs=-1)\n",
                "    rf.fit(X_train_feat[tr_i], y_train[tr_i])\n",
                "    rf_oof[val_i] = rf.predict_proba(X_train_feat[val_i])\n",
                "    rf_test += rf.predict_proba(X_test_feat) / N_FOLDS\n",
                "    print(f\"  RF:  {rf.score(X_train_feat[val_i], y_train[val_i]):.4f}\")\n",
                "    \n",
                "    # HistGradientBoosting\n",
                "    hgb = HistGradientBoostingClassifier(max_iter=100, max_depth=10, random_state=SEED+fold)\n",
                "    hgb.fit(X_train_feat[tr_i], y_train[tr_i])\n",
                "    hgb_oof[val_i] = hgb.predict_proba(X_train_feat[val_i])\n",
                "    hgb_test += hgb.predict_proba(X_test_feat) / N_FOLDS\n",
                "    print(f\"  HGB: {hgb.score(X_train_feat[val_i], y_train[val_i]):.4f}\")\n",
                "    \n",
                "    print(f\"  Time: {(time.time()-t1)/60:.1f}min\")\n",
                "\n",
                "print(f\"\\nTotal: {(time.time()-t0)/60:.1f}min\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Individual CV Accuracy:\n",
                        "  CNN: 0.5028\n",
                        "  ET:  0.5056\n",
                        "  RF:  0.5028\n",
                        "  HGB: 0.4944\n",
                        "\n",
                        "Best: CNN=0.5, ET=0.3, RF=0.1, HGB=0.1\n",
                        "Ensemble CV: 0.5139\n"
                    ]
                }
            ],
            "source": [
                "# Cell 7: Ensemble\n",
                "print(\"Individual CV Accuracy:\")\n",
                "print(f\"  CNN: {accuracy_score(y_train, cnn_oof.argmax(1)):.4f}\")\n",
                "print(f\"  ET:  {accuracy_score(y_train, et_oof.argmax(1)):.4f}\")\n",
                "print(f\"  RF:  {accuracy_score(y_train, rf_oof.argmax(1)):.4f}\")\n",
                "print(f\"  HGB: {accuracy_score(y_train, hgb_oof.argmax(1)):.4f}\")\n",
                "\n",
                "# Grid search weights\n",
                "best_acc, best_w = 0, None\n",
                "for w1 in np.arange(0.2, 0.6, 0.1):  # CNN\n",
                "    for w2 in np.arange(0.1, 0.4, 0.1):  # ET\n",
                "        for w3 in np.arange(0.1, 0.4, 0.1):  # RF\n",
                "            w4 = 1 - w1 - w2 - w3\n",
                "            if w4 < 0: continue\n",
                "            oof = w1*cnn_oof + w2*et_oof + w3*rf_oof + w4*hgb_oof\n",
                "            acc = accuracy_score(y_train, oof.argmax(1))\n",
                "            if acc > best_acc:\n",
                "                best_acc, best_w = acc, (w1, w2, w3, w4)\n",
                "\n",
                "print(f\"\\nBest: CNN={best_w[0]:.1f}, ET={best_w[1]:.1f}, RF={best_w[2]:.1f}, HGB={best_w[3]:.1f}\")\n",
                "print(f\"Ensemble CV: {best_acc:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved: submission_milestone2_v4.csv\n",
                        "\n",
                        "Distribution:\n",
                        "Label\n",
                        "0    239\n",
                        "1     50\n",
                        "2     47\n",
                        "3     58\n",
                        "4      6\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Total time: 14.3min\n"
                    ]
                }
            ],
            "source": [
                "# Cell 8: Submission\n",
                "w1, w2, w3, w4 = best_w\n",
                "final = w1*cnn_test + w2*et_test + w3*rf_test + w4*hgb_test\n",
                "preds = final.argmax(1)\n",
                "\n",
                "# IMPORTANT: ID starts from 1!\n",
                "submission = pd.DataFrame({'ID': np.arange(1, n_test + 1), 'Label': preds})\n",
                "submission.to_csv('submission_milestone2_v4.csv', index=False)\n",
                "\n",
                "print(\"Saved: submission_milestone2_v4.csv\")\n",
                "print(f\"\\nDistribution:\\n{submission['Label'].value_counts().sort_index()}\")\n",
                "print(f\"\\nTotal time: {(time.time()-t0)/60:.1f}min\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
